{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOd5BbZXGcT0PQ75SHTy0vF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calicartels/XAI-in-LLMS/blob/main/XAI_in_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PDzK09SMogJq"
      },
      "outputs": [],
      "source": [
        "!pip install umap-learn plotly\n",
        "!pip install datasets\n",
        "!pip install transformers sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Login using my credentials:\n",
        "\n",
        "my_secret_key = userdata.get(\"HF_TOKEN\")\n",
        "login(my_secret_key)"
      ],
      "metadata": {
        "id": "9UgKqJOy5uPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import umap\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = 'colab'\n",
        "\n",
        "\n",
        "# Sample text data to get embeddings:\n",
        "texts = [\n",
        "    \"The quick brown fox jumps over the lazy dog\",\n",
        "    \"Machine learning is transforming the world\",\n",
        "    \"Natural language processing is fascinating\",\n",
        "    \"Deep learning models are becoming more powerful\",\n",
        "    \"Artificial intelligence continues to evolve\",\n",
        "    \"Data science helps us understand patterns\",\n",
        "    \"Neural networks learn from examples\",\n",
        "    \"Computer vision can recognize objects\",\n",
        "    \"Robotics combines hardware and software\",\n",
        "    \"Cloud computing enables scalability\",\n",
        "    \"The Internet revolutionized communication\",\n",
        "    \"Big data drives business decisions\",\n",
        "    \"Quantum computing explores new frontiers\",\n",
        "    \"Cybersecurity protects digital assets\",\n",
        "    \"Edge computing reduces latency\",\n",
        "    \"Blockchain ensures data integrity\",\n",
        "    \"Virtual reality creates immersive experiences\",\n",
        "    \"Augmented reality enhances reality\",\n",
        "    \"5G networks enable faster connectivity\",\n",
        "    \"Internet of Things connects devices\"\n",
        "]\n",
        "\n",
        "# Model 1: Nvidia's Embed v1 model\n",
        "\n",
        "def get_nv_embeddings(texts):\n",
        "    try:\n",
        "        model = SentenceTransformer('nvidia/nv-embed-v1',\n",
        "                                   token=my_secret_key,\n",
        "                                   trust_remote_code=True)\n",
        "        embeddings = model.encode(texts)\n",
        "        return embeddings\n",
        "    except Exception as e:\n",
        "        print(f\"Error with NV-Embed-v1: {str(e)}\")\n",
        "        print(\"Falling back to all-MiniLM-L6-v2...\")\n",
        "        model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "        return model.encode(texts)\n",
        "\n",
        "# Model 2: Linkedin's Embed model\n",
        "\n",
        "def get_linq_embeddings(texts):\n",
        "    try:\n",
        "        model = SentenceTransformer('linkedin/linq-embed-mistral',\n",
        "                                   token=my_secret_key)\n",
        "        embeddings = model.encode(texts)\n",
        "        return embeddings\n",
        "    except Exception as e:\n",
        "        print(f\"Error with Linq-Embed-Mistral: {str(e)}\")\n",
        "        print(\"Falling back to all-MiniLM-L6-v2...\")\n",
        "        model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "        return model.encode(texts)\n",
        "\n",
        "# Model 3 : Beijing's AI academy's Embed model\n",
        "\n",
        "def get_bge_embeddings(texts):\n",
        "    model = SentenceTransformer('BAAI/bge-large-en-v1.5')\n",
        "    embeddings = model.encode(texts, normalize_embeddings=True)\n",
        "    return embeddings\n"
      ],
      "metadata": {
        "id": "pjzJlpmOsCZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_dimensions(embeddings):\n",
        "\n",
        "    # PCA\n",
        "    pca = PCA(n_components=3)\n",
        "    pca_result = pca.fit_transform(embeddings)\n",
        "\n",
        "    # t-SNE\n",
        "    tsne = TSNE(n_components=3,\n",
        "                random_state=42,\n",
        "                perplexity=5,\n",
        "                n_iter=1000)\n",
        "    tsne_result = tsne.fit_transform(embeddings)\n",
        "\n",
        "    # UMAP\n",
        "    umap_reducer = umap.UMAP(n_components=3,\n",
        "                            random_state=42,\n",
        "                            n_neighbors=5)\n",
        "    umap_result = umap_reducer.fit_transform(embeddings)\n",
        "\n",
        "    return pca_result, tsne_result, umap_result"
      ],
      "metadata": {
        "id": "Ac_QmjGiLQdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_visualization(reduced_data, texts, method_name, model_name):\n",
        "    df = pd.DataFrame(\n",
        "        reduced_data,\n",
        "        columns=['Dimension 1', 'Dimension 2', 'Dimension 3']\n",
        "    )\n",
        "    df['Text'] = texts\n",
        "\n",
        "    fig = px.scatter_3d(\n",
        "        df,\n",
        "        x='Dimension 1',\n",
        "        y='Dimension 2',\n",
        "        z='Dimension 3',\n",
        "        text='Text',\n",
        "        title=f'{method_name} visualization of {model_name} embeddings',\n",
        "        labels={'Text': 'Document'},\n",
        "        hover_data=['Text']\n",
        "    )\n",
        "\n",
        "    # Update layout for better visibility\n",
        "    fig.update_layout(\n",
        "        width=800,\n",
        "        height=800,\n",
        "        showlegend=False,\n",
        "        scene=dict(\n",
        "            xaxis_title='Dimension 1',\n",
        "            yaxis_title='Dimension 2',\n",
        "            zaxis_title='Dimension 3'\n",
        "        ),\n",
        "        title=dict(\n",
        "            y=0.95,\n",
        "            x=0.5,\n",
        "            xanchor='center',\n",
        "            yanchor='top'\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Update markers\n",
        "    fig.update_traces(\n",
        "        marker=dict(size=8, opacity=0.8),\n",
        "        textposition='top center',\n",
        "        hoverinfo='text'\n",
        "    )\n",
        "\n",
        "    # Display the figure\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "uLnLtHbKLYyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Generate embeddings using different models\n",
        "    models = {\n",
        "        'NV-Embed-v1': get_nv_embeddings,\n",
        "        'Linq-Embed-Mistral': get_linq_embeddings,\n",
        "        'BGE-EN-ICL': get_bge_embeddings\n",
        "    }\n",
        "\n",
        "    for model_name, embedding_func in models.items():\n",
        "        print(f\"\\nProcessing {model_name} embeddings...\")\n",
        "\n",
        "        try:\n",
        "            # Generate embeddings\n",
        "            embeddings = embedding_func(texts)\n",
        "\n",
        "            # Apply dimensionality reduction\n",
        "            pca_result, tsne_result, umap_result = reduce_dimensions(embeddings)\n",
        "\n",
        "            # Create visualizations\n",
        "            methods = {\n",
        "                'PCA': pca_result,\n",
        "                't-SNE': tsne_result,\n",
        "                'UMAP': umap_result\n",
        "            }\n",
        "\n",
        "            print(f\"\\nGenerating visualizations for {model_name}...\")\n",
        "            for method_name, reduced_data in methods.items():\n",
        "                print(f\"Displaying {method_name} plot...\")\n",
        "                create_visualization(reduced_data, texts, method_name, model_name)\n",
        "                print(f\"Created {method_name} visualization for {model_name}\")\n",
        "\n",
        "                # Add a small delay between plots for better display\n",
        "                import time\n",
        "                time.sleep(1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {model_name}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "_pI1FzjyzoD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Principal Component Analysis : it misses nuanced clusters in complex datasets because it focuses on linear structures.\n",
        "2. t-SNE, excellent for visualizing dense clusters and discovering hidden groupings, although it often distorts the global arrangement between clusters.\n",
        "Although in my case, it is more suited to becasue of the dataset size being small.\n",
        "\n",
        "3. UMAP, faster than t-SNE, scales well with larger datasets, and reveals relationships within and between clusters. Shows out large distances between the embeddings"
      ],
      "metadata": {
        "id": "X3gNlLp3PZ2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "[1] https://huggingface.co/docs/huggingface_hub/en/guides/cli#huggingface-cli-login\n",
        "\n",
        "[2] https://www.youtube.com/watch?v=7iAe3DmIXJY\n",
        "\n",
        "[3] Claude for error debugging"
      ],
      "metadata": {
        "id": "AVzPuwD-Li_6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYxY0nK3LKyt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}